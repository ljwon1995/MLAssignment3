{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1027, shuffle=False, num_workers=1)  \n",
    "\n",
    "validation_data_path = './horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1027, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "trainList = list()\n",
    "validList = list()\n",
    "trainLabelList = list()\n",
    "validLabelList = list()\n",
    "\n",
    "for i, data in enumerate(trainloader):\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    # change inputs to matrix 10000*batch_size\n",
    "    for bat_idx in range(batch_size):\n",
    "\n",
    "        targMat = inputs[bat_idx][0]\n",
    "\n",
    "        colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "\n",
    "        if(bat_idx == 0):\n",
    "            batMat = colVec\n",
    "        else:\n",
    "            batMat = np.concatenate((batMat, colVec), axis = 1)         \n",
    "\n",
    "    # Add ones because of the value b in coefficient\n",
    "    ones = np.ones((1, batch_size), dtype = int)\n",
    "    batMat = np.concatenate((batMat, ones))\n",
    "    trainList.append(batMat)\n",
    "    trainLabelList.append(labels)\n",
    "    \n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "     # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "    # Change Inputs to matrix 10000*batch_size\n",
    "\n",
    "    for bat_idx in range(batch_size):\n",
    "        targMat = inputs[bat_idx][0]\n",
    "        colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "\n",
    "        if(bat_idx == 0):\n",
    "            batMat = colVec\n",
    "        else:\n",
    "            batMat = np.concatenate((batMat,colVec), axis = 1)\n",
    "        \n",
    "    # Add ones because of the value b in coefficient\n",
    "    ones = np.ones((1, batch_size), dtype = int)\n",
    "    batMat = np.concatenate((batMat, ones))\n",
    "    validList.append(batMat)\n",
    "    validLabelList.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027\n",
      "epoch :  0 , lrnCor :  500 valCor :  128 elapsed time :  0.16585493087768555 total loss :  0.6931471805599451\n",
      "epoch :  1 , lrnCor :  527 valCor :  128 elapsed time :  0.16844511032104492 total loss :  0.6957726069597276\n",
      "epoch :  2 , lrnCor :  500 valCor :  128 elapsed time :  0.17217588424682617 total loss :  0.718465049963566\n",
      "epoch :  3 , lrnCor :  527 valCor :  128 elapsed time :  0.1835787296295166 total loss :  0.9033107197538419\n",
      "epoch :  4 , lrnCor :  500 valCor :  128 elapsed time :  0.13922929763793945 total loss :  1.8920893169239883\n",
      "epoch :  5 , lrnCor :  527 valCor :  128 elapsed time :  0.08782315254211426 total loss :  3.053557582977534\n",
      "epoch :  6 , lrnCor :  500 valCor :  128 elapsed time :  0.09336304664611816 total loss :  2.1146963925620694\n",
      "epoch :  7 , lrnCor :  527 valCor :  128 elapsed time :  0.16230392456054688 total loss :  3.183005102139598\n",
      "epoch :  8 , lrnCor :  500 valCor :  128 elapsed time :  0.24717116355895996 total loss :  2.0018555152529958\n",
      "epoch :  9 , lrnCor :  527 valCor :  128 elapsed time :  0.1358509063720703 total loss :  3.2611286289891455\n",
      "epoch :  10 , lrnCor :  500 valCor :  128 elapsed time :  0.11320018768310547 total loss :  1.9326517197838287\n",
      "epoch :  11 , lrnCor :  527 valCor :  128 elapsed time :  0.17001891136169434 total loss :  3.3038098407265495\n",
      "epoch :  12 , lrnCor :  500 valCor :  128 elapsed time :  0.1309199333190918 total loss :  1.8955306517453168\n",
      "epoch :  13 , lrnCor :  527 valCor :  128 elapsed time :  0.11612105369567871 total loss :  3.3256693024344504\n",
      "epoch :  14 , lrnCor :  500 valCor :  128 elapsed time :  0.10867619514465332 total loss :  1.8774037557668573\n",
      "epoch :  15 , lrnCor :  527 valCor :  128 elapsed time :  0.10412406921386719 total loss :  3.3367466291128065\n",
      "epoch :  16 , lrnCor :  500 valCor :  128 elapsed time :  0.17856192588806152 total loss :  1.8689873514516018\n",
      "epoch :  17 , lrnCor :  527 valCor :  128 elapsed time :  0.09014296531677246 total loss :  3.3425950220743132\n",
      "epoch :  18 , lrnCor :  500 valCor :  128 elapsed time :  0.08777284622192383 total loss :  1.8651382669768644\n",
      "epoch :  19 , lrnCor :  527 valCor :  128 elapsed time :  0.07940983772277832 total loss :  3.345942338055773\n",
      "epoch :  20 , lrnCor :  500 valCor :  128 elapsed time :  0.09395694732666016 total loss :  1.8633578945655018\n",
      "epoch :  21 , lrnCor :  527 valCor :  128 elapsed time :  0.09129905700683594 total loss :  3.348062364170779\n",
      "epoch :  22 , lrnCor :  500 valCor :  128 elapsed time :  0.08631587028503418 total loss :  1.8625060335350303\n",
      "epoch :  23 , lrnCor :  527 valCor :  128 elapsed time :  0.12216997146606445 total loss :  3.3495448014529985\n",
      "epoch :  24 , lrnCor :  500 valCor :  128 elapsed time :  0.1338801383972168 total loss :  1.862075171149709\n",
      "epoch :  25 , lrnCor :  527 valCor :  128 elapsed time :  0.09403800964355469 total loss :  3.350668081911833\n",
      "epoch :  26 , lrnCor :  500 valCor :  128 elapsed time :  0.10136890411376953 total loss :  1.8618403375628594\n",
      "epoch :  27 , lrnCor :  527 valCor :  128 elapsed time :  0.08101224899291992 total loss :  3.351569434240913\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e49f864112cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mdLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainLabelList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                   \u001b[0;31m#change tensor type to double\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdLabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0msumL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Initialize Coef to Zeros\n",
    "\n",
    "w_0 = np.zeros((1,10001), dtype = float)\n",
    "a = np.ones((1,10001), dtype = float)\n",
    "w_0 =np.concatenate((w_0, a), axis = 0)\n",
    "a = 2 * np.ones((1,10001), dtype = float)\n",
    "w_0 =np.concatenate((w_0, a), axis = 0)\n",
    "a = 3 * np.ones((1,10001), dtype = float)\n",
    "w_0 =np.concatenate((w_0, a), axis = 0)\n",
    "totalDataNum = len(trainloader.dataset)\n",
    "print(totalDataNum)\n",
    "\n",
    "\n",
    "w_1 = np.array([[0,0,0,0],\n",
    "              [1,1,1,1],\n",
    "              [2,2,2,2]], dtype = float)\n",
    "\n",
    "w_2 = np.zeros((1, 3), dtype = float)\n",
    "\n",
    "#Set Learning Rate\n",
    "lrnRate = 0.007\n",
    "\n",
    "# Set Loss Lists\n",
    "lrnLoss = list()\n",
    "valLoss = list()\n",
    "\n",
    "# Set Accurate Lists\n",
    "lrnAcc = list()\n",
    "valAcc = list()\n",
    "\n",
    "# set Elapsed time Lists\n",
    "elapTime = list()\n",
    "\n",
    "\n",
    "epoch = -1\n",
    "lrnAccRate = 0\n",
    "\n",
    "while(lrnAccRate < 0.85):\n",
    "    epoch += 1\n",
    "\n",
    "\n",
    "    \n",
    "    #Set Sum of Loss to 0\n",
    "    sumL = 0\n",
    "    \n",
    "    #Set Sum of Cor to 0\n",
    "    cor = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, a_0 in enumerate(trainList):\n",
    "        \n",
    "        batch_size = a_0.shape[1]\n",
    "\n",
    "        # Start Regression Calculation\n",
    "        z_0 = np.dot(w_0, a_0)          \n",
    "\n",
    "        a_1 = 1/(1 + np.exp(-z_0))                                               \n",
    "        z_1 = np.dot(w_1, a_1)\n",
    "        a_2 = 1/(1 + np.exp(-z_1))\n",
    "        \n",
    "        z_2 = np.dot(w_2, a_2)\n",
    "        a_3 = 1/(1 + np.exp(-z_2))\n",
    "   \n",
    "        \n",
    "    \n",
    "        dz_2 = np.subtract(a_3, trainLabelList[i])  \n",
    "\n",
    "        dw_2 = np.dot(dz_2, a_2.T) \n",
    "        w_2 -= lrnRate * dw_2\n",
    "        \n",
    "        da_2 = np.dot(w_2.T, dz_2)\n",
    "        dz_1 = da_2 * a_2 * (1 - a_2) \n",
    "        dw_1 = np.dot(dz_1, a_1.T)\n",
    "        w_1 -= lrnRate * dw_1\n",
    "        \n",
    "        da_1 = np.dot(w_1.T, dz_1)\n",
    "        dz_0 = da_1 * a_1 * (1 - a_1)\n",
    "        dw_0 = np.dot(dz_0, a_0.T)\n",
    "        w_0 -= lrnRate * dw_0\n",
    "\n",
    "        \n",
    "        # Calculate Total Loss\n",
    "        a_3 = torch.from_numpy(a_3)                                             #change ndarray to tensor\n",
    "        dLabels = trainLabelList[i].double()                                   #change tensor type to double\n",
    "        L = -(dLabels) * np.log(a_3) - (1-dLabels) * np.log(1-a_3)      \n",
    "        sumL += L.sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate Accuracy\n",
    "\n",
    "\n",
    "        for batIdx in range(batch_size):\n",
    "\n",
    "            if(a_3[0][batIdx] <= 0.5 and trainLabelList[i][batIdx] == 0):\n",
    "                cor += 1\n",
    "\n",
    "            if(a_3[0][batIdx] > 0.5 and trainLabelList[i][batIdx] == 1):\n",
    "                cor += 1\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    # Calculate dLossdCoef\n",
    "    \n",
    "    \n",
    "\n",
    "    # Update coefs using derivatives\n",
    "    \n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    elapTime.append(elapsed_time)\n",
    "\n",
    "\n",
    "    # Calculate TotalLoss\n",
    "    sumL /= totalDataNum\n",
    "\n",
    "    lrnLoss.append(sumL)\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    \n",
    "    lrnAccRate = cor/totalDataNum\n",
    "    lrnAcc.append(lrnAccRate)\n",
    "    \n",
    "                \n",
    "\n",
    "\n",
    "    # Set Sum Of Valid Loss to 0\n",
    "    sumVL = 0\n",
    "    # Set Sum of Valid Cor to 0\n",
    "    vCor = 0\n",
    "    \n",
    "    # load validation images of the batch size for every iteration\n",
    "    for i, a_0 in enumerate(validList):\n",
    "        \n",
    "        \n",
    "        batch_size = batMat.shape[1]\n",
    "        \n",
    "        # Start Calculate Loss \n",
    "        z_0 = np.dot(w_0, a_0)\n",
    "        a_1= 1/(1+np.exp(-z_0))\n",
    "        \n",
    "        z_1 = np.dot(w_1, a_1)\n",
    "        a_2= 1/(1+np.exp(-z_1))\n",
    "        \n",
    "        z_2 = np.dot(w_2, a_2)\n",
    "        a_3= 1/(1+np.exp(-z_2))\n",
    "        \n",
    "        \n",
    "        a_3 = torch.from_numpy(a_3)\n",
    "        dLabels = validLabelList[i].double()\n",
    "        L = -(dLabels) * np.log(a_3) - (1-dLabels) * np.log(1-a_3)\n",
    "        sumVL += L.sum()\n",
    "\n",
    "        \n",
    "        # Calculate Accuracy\n",
    "        \n",
    "        for batIdx in range(batch_size):\n",
    "            if(a_3[0][batIdx] <= 0.5 and validLabelList[i][batIdx] == 0):\n",
    "                vCor += 1\n",
    "                \n",
    "            if(a_3[0][batIdx] > 0.5 and validLabelList[i][batIdx] == 1):\n",
    "                vCor += 1\n",
    "    \n",
    "    totalValDataNum = len(valloader.dataset)\n",
    "    \n",
    "    # CalCulate Total Loss\n",
    "    sumVL /= totalValDataNum\n",
    "    valLoss.append(sumVL)\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    vAcc = vCor/totalValDataNum\n",
    "    valAcc.append(vAcc)\n",
    "    \n",
    "    \n",
    "    print(\"epoch : \",epoch,',', \"lrnCor : \", cor, \"valCor : \", vCor, \"elapsed time : \", elapsed_time, \"total loss : \", sumL.item())\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(elapTime, color = 'black', label = \"ElapsedTime\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"time\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,4))\n",
    "\n",
    "\n",
    "axs[0].plot(lrnLoss, color = 'red', label = \"TrainingLoss\")\n",
    "\n",
    "\n",
    "axs[1].plot(valLoss, color = 'blue', label = \"ValidationLoss\")\n",
    "\n",
    "axs[0].set(ylabel = 'Loss')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Loss')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,5))\n",
    "\n",
    "\n",
    "axs[0].plot(lrnAcc, color = 'orange', label = \"TrainingAccuracy\")\n",
    "\n",
    "\n",
    "axs[1].plot(valAcc, color = 'green', label = \"ValidationAccuracy\")\n",
    "\n",
    "axs[0].set(ylabel = 'Accuracy')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Accuracy')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Altogether\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.title('Altogether')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.plot(lrnLoss, color = 'red', label = 'TrainingLoss')\n",
    "plt.plot(valLoss, color = 'blue', label = \"ValidationLoss\")\n",
    "plt.plot(lrnAcc, color = 'orange', label = \"TrainingAccuracy\")\n",
    "plt.plot(valAcc, color = 'green', label = \"ValidationAccuracy\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  Dataset   |   Loss   | Accuracy\")\n",
    "\n",
    "print(\"  Training  | %.4f | %.4f\" % (lrnLoss[-1], lrnAcc[-1]))\n",
    "print(\" Validation| %.4f | %.4f\" % (valLoss[-1], valAcc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0 = np.zeros((1,10001), dtype = float)\n",
    "print(\"w = \", w_0)\n",
    "\n",
    "a = np.ones((1,3), dtype = float)\n",
    "print(\"a = \" ,a)\n",
    "w_0 =np.concatenate((w_0, a), axis = 0)\n",
    "print(\"w = \", w_0)\n",
    "b = 2 * np.ones((1,3), dtype = float)\n",
    "print(b)\n",
    "w_0 =np.concatenate((w_0, b), axis = 0)\n",
    "print(\"w = \", w_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
